{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This website provides technical documentation for the <code>eligibility-server</code> application, a part of the <code>benefits</code> application, from the California Integrated Travel Project (Cal-ITP).</p> <p>Eligibility Server is open-source software that is designed, developed, and maintained by Compiler LLC on behalf of Caltrans, Cal-ITP, and our agency partners.</p>"},{"location":"#overview","title":"Overview","text":"<p><code>eligibility-server</code> is a Flask web application that implements an Eligibility Verification API.</p> <p>The API is designed for privacy and security of user information:</p> <ul> <li>The API communicates with signed and encrypted JSON Web Tokens containing only the most necessary of user data for the purpose of eligibility verification</li> <li>The application requires no user accounts and stores no information about the user</li> <li>Interaction with the application is anonymous, with only minimal event tracking for usage and problem analysis</li> </ul> <p>The server is published as a Docker container on the GitHub Container Registry.</p>"},{"location":"#getting-started-with-the-app","title":"Getting started with the app","text":"<p>Running the application locally is possible with Docker and Docker Compose.</p>"},{"location":"#build-the-docker-container-for-local-development","title":"Build the Docker container for local development","text":"<pre><code>cp .env.sample .env\ndocker compose build server\n</code></pre>"},{"location":"#use-the-docker-container-locally","title":"Use the Docker container locally","text":"<pre><code>docker pull ghcr.io/cal-itp/eligibility-server:dev\n</code></pre>"},{"location":"getting-started/","title":"Getting started","text":"<p>Running the Eligibility Server application in a local, non-production environment requires Docker.</p>"},{"location":"getting-started/#running-the-app-locally-for-development","title":"Running the app locally for development","text":"<p>The following commands should be run in a terminal program like <code>bash</code>.</p>"},{"location":"getting-started/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/cal-itp/eligibility-server.git\ncd eligibility-server\n</code></pre>"},{"location":"getting-started/#create-an-environment-file","title":"Create an environment file","text":"<p>Use the sample as the template.</p> <pre><code>cp .env.sample .env\n</code></pre> <p>The .env file specifies the following value:</p> <ul> <li><code>ELIGIBILITY_SERVER_SETTINGS</code>: Path to a Python configuration file which will override default settings</li> </ul> <p>See Configuration for more details on supported settings.</p>"},{"location":"getting-started/#build-image-using-docker-compose","title":"Build image using Docker Compose","text":"<pre><code>./bin/build.sh\n</code></pre>"},{"location":"getting-started/#start-the-server","title":"Start the server","text":"<pre><code>docker compose up [-d] server\n</code></pre> <p>The optional <code>-d</code> flag will start in detatched mode and allow you to continue using the terminal session. Otherwise your terminal will be attached to the container\u2019s terminal, showing the startup and runtime output.</p> <p>After initialization, the server is running on <code>http://localhost</code> at a port dynamically assigned by Docker. See Docker dynamic ports for more information on accessing the site on localhost.</p>"},{"location":"getting-started/#run-healthcheck","title":"Run healthcheck","text":"<p>To check if the server is running successfully, use your browser to get to the Healthcheck endpoint: <code>http://localhost:50252/healthcheck</code></p> <p>The page should read \u201cHealthy\u201d</p>"},{"location":"getting-started/#stop-the-server","title":"Stop the server","text":"<pre><code>docker compose down\n</code></pre>"},{"location":"getting-started/#develop-with-vs-code-remote-containers","title":"Develop with VS Code Remote Containers","text":"<p>This repository comes with a VS Code Remote Containers configuration file.</p> <p>Once you clone the repository locally, open it within VS Code, which will prompt you to re-open the repository within the Remote Container.</p> <ol> <li>Build and Open the Dev Container</li> <li>Start the <code>eligibility-server</code> Flask app and database with <code>F5</code></li> <li>Now you can run tests from the container.</li> </ol> <p>Starting the Dev Container will run <code>bin/init.sh</code>, which runs a command to initialize the database. More specifically, it creates the database and imports and saves users based on the configured settings.</p>"},{"location":"getting-started/#run-tests","title":"Run tests","text":""},{"location":"getting-started/#run-unit-tests","title":"Run unit tests","text":"<p>Unit tests are implemented with <code>pytest</code> and can be found in the <code>tests/</code> directory in the repository. <code>pytest</code> is installed and available to run directly in the devcontainer.</p> <p>The test suite runs against every pull request via a GitHub Action.</p>"},{"location":"getting-started/#destroy-and-recreate-database","title":"Destroy and recreate database","text":"<p>In testing the database, you may need to teardown the database and restart a database from scratch.</p> <p>The command below will remove all users and drop the database:</p> <pre><code>flask drop-db\n</code></pre> <p>To set up the database with a new import file or other configuration variables, after making any new environment variable changes, run:</p> <pre><code>flask init-db\n</code></pre>"},{"location":"getting-started/#run-and-develop-the-documentation","title":"Run and develop the Documentation","text":"<p>These docs are built and published with GitHub Actions.</p> <p>To run the docs locally:</p> <pre><code>docker compose up docs\n</code></pre> <p>Read more on how to run the docs locally.</p>"},{"location":"releases/","title":"Releases","text":"<p>The <code>eligibility-server</code> is published as a Docker image on the GitHub Container Registry. It can be accessed from the repository package page.</p> <p>Every push to the <code>main</code> (default) branch that changes files relevant to the application builds and pushes a new package tagged with the corresponding Git commit hash, via the <code>docker-publish</code> GitHub Action.</p> <p>Commits that are tagged with our version number format for release candidates and releases will also push a new package.</p>"},{"location":"releases/#versions","title":"Versions","text":"<p>All versions of the package may be viewed on the package all versions page.</p>"},{"location":"releases/#version-number-format","title":"Version number format","text":"<p><code>eligibility-server</code> uses the CalVer versioning scheme, where version numbers for releases look like: <code>YYYY.0M.R</code></p> <ul> <li><code>YYYY</code> is the 4-digit year of the release; e.g. <code>2021</code>, <code>2022</code></li> <li><code>0M</code> is the 2-digit, 0-padded month of the release; e.g. <code>02</code> is February, <code>12</code>   is December.</li> <li><code>R</code> is the 1-based release counter for the given year and month;   e.g. <code>1</code> for the first release of the month, <code>2</code> for the second, and so on.</li> </ul> <p>Version numbers for release candidates append <code>-rcR</code>, where <code>R</code> is the 1-based release counter for the anticipated release. For example, the first release candidate for the <code>2024.01.1</code> release would be <code>2024.01.1-rc1</code>.</p>"},{"location":"releases/#making-a-release","title":"Making a release","text":"<p>This list outlines the manual steps needed to make a new release of <code>eligibility-server</code>.</p> <p>A release is made by pushing an annotated tag. The name of the tag must use the version number format mentioned above. This kicks off a deployment to the production environment and creates a GitHub release. The version number for the app and the release will be the tag\u2019s name.</p> <p>More details about the deployment steps and release creation can be found in the <code>docker-publish</code> workflow. <code>release</code> workflow.</p> <p>The list of releases can be found on the repository Releases page on GitHub.</p> <p>Start a new Release on Github</p>"},{"location":"releases/#1-create-a-release-candidate-tag-on-main-and-push-it","title":"1. Create a release candidate tag on <code>main</code> and push it","text":"<pre><code>git fetch\ngit checkout main\ngit reset --hard origin/main\ngit tag -a YYYY.0M.R-rcR\n</code></pre> <p>Git will open your default text editor and prompt you for the tag annotation. For the tag annotation, use the release candidate version. Finally, after closing the text editor:</p> <pre><code>git push origin YYYY.0M.R-rcR\n</code></pre> <p>This builds a new package and deploys to the Azure test environments. No GitHub release is created for release candidates.</p>"},{"location":"releases/#2-create-a-release-tag-on-main-and-push-it","title":"2. Create a release tag on <code>main</code> and push it","text":"<pre><code>git fetch\ngit checkout main\ngit reset --hard origin/main\ngit tag -a YYYY.0M.R\n</code></pre> <p>Git will open your default text editor and prompt you for the tag annotation. For the tag annotation, use the title of the release-tagged Issue that kicked off the release. Finally, after closing the text editor:</p> <pre><code>git push origin YYYY.0M.R\n</code></pre> <p>This builds the package and deploys to the Azure production environments. A GitHub release is created.</p>"},{"location":"releases/#3-generate-release-notes","title":"3. Generate release notes","text":"<p>Edit release notes with additional context, images, animations, etc. as-needed and link to the release issue.</p>"},{"location":"configuration/","title":"Configuring the Eligibility server","text":"<p>The Getting Started section mentions copying <code>.env.sample</code> to <code>.env</code> as a template. These sample values are sufficient to configure the server to be run locally.</p> <p>If you want to run with different settings, you should:</p> <ol> <li>Create a new Python configuration file in the <code>config</code> directory</li> <li>Provide a value for <code>IMPORT_FILE_PATH</code> (required) and any other settings you want to override (optional)</li> <li>Set the <code>ELIGIBILITY_SERVER_SETTINGS</code> environment variable to the path of your new file</li> </ol> <p>Note</p> <p>The Eligibility server loads in settings using Flask\u2019s methods for Configuration Handling.</p> <p>Note</p> <p>The default settings that will always be loaded are in eligibility_server/settings.py</p>"},{"location":"configuration/#creating-a-new-keypair","title":"Creating a new keypair","text":"<p>Warning</p> <p>The sample keys cannot be used for production. You must create and use a new keypair.</p> <p>To create a new keypair, start by creating the private key e.g. using OpenSSL:</p> <pre><code>openssl genrsa -out private.pem -traditional 4096\n</code></pre> <p>Next, extract the public key e.g. using OpenSSL:</p> <pre><code>openssl rsa -in private.pem -pubout -out public.pem\n</code></pre> <p>Now there are two files:</p> <ul> <li>The private key, kept secret for this server instance only: <code>private.pem</code></li> <li>The public key, shared with all clients of this server: <code>public.pem</code></li> </ul> <p>The server instance also needs a public key reference from its client, so the above process should be repeated on the client- side and the client\u2019s public key should be shared with the server.</p>"},{"location":"configuration/settings/","title":"Settings","text":"<p>The sections below outline in more detail the settings that you either must set or may want to override, and their purpose.</p> <p><code>*</code> Asterisk indicates a setting that you must set</p>"},{"location":"configuration/settings/#app-settings","title":"App settings","text":""},{"location":"configuration/settings/#agency_name","title":"<code>AGENCY_NAME</code>","text":"<p>The name of the agency that this server is deployed for</p>"},{"location":"configuration/settings/#app_name","title":"<code>APP_NAME</code>","text":"<p>The name set on the Flask app</p>"},{"location":"configuration/settings/#debug_mode","title":"<code>DEBUG_MODE</code>","text":"<p>Value passed as a keyword argument for <code>debug</code> in <code>app.run</code></p>"},{"location":"configuration/settings/#host","title":"<code>HOST</code>","text":"<p>Value passed as a keyword argument for <code>host</code> in <code>app.run</code></p>"},{"location":"configuration/settings/#log_level","title":"<code>LOG_LEVEL</code>","text":"<p>The log level used for the server\u2019s logging.</p>"},{"location":"configuration/settings/#database-settings","title":"Database settings","text":"<p>Note</p> <p>See other configurable settings from Flask-SQLAlchemy.</p>"},{"location":"configuration/settings/#sqlalchemy_database_uri","title":"<code>SQLALCHEMY_DATABASE_URI</code>","text":"<p>The URI that should be used for database connection.</p>"},{"location":"configuration/settings/#api-settings","title":"API settings","text":"<p>These settings configure access to the API endpoints on the server.</p>"},{"location":"configuration/settings/#auth_header","title":"<code>AUTH_HEADER</code>","text":"<p>The header name that the server expects to see from authenticated/authorized requests.</p> <p>See the Eligibility API\u2019s documentation on Authentication/Authorization.</p>"},{"location":"configuration/settings/#auth_token","title":"<code>AUTH_TOKEN</code>","text":"<p>The header value that the server expects to see from authenticated/authorized requests.</p> <p>See the Eligibility API\u2019s documentation on Authentication/Authorization.</p>"},{"location":"configuration/settings/#token_header","title":"<code>TOKEN_HEADER</code>","text":"<p>The header name that the server expects to see for the header containing the Eligibility Verification request token.</p>"},{"location":"configuration/settings/#eligibility-verification-settings","title":"Eligibility Verification settings","text":"<p>These settings configure how the server parses, composes, and validates requests and responses according to the Eligibility API specification.</p>"},{"location":"configuration/settings/#client_key_path","title":"<code>CLIENT_KEY_PATH</code>","text":"<p>The path to the Eligibility Verification client\u2019s public key, stored as a PEM text file. Used to verify the client\u2019s request signature, and to encrypt the server\u2019s response.</p> <p>Can be a path to a local file or a remote URL. For URLs, a simple anonymous GET request is made.</p>"},{"location":"configuration/settings/#jwe_cek_enc","title":"<code>JWE_CEK_ENC</code>","text":"<p>The value used for <code>enc</code> in the JOSE header of the JWE.</p> <p>See the Eligibility API\u2019s documentation on Composing a message.</p>"},{"location":"configuration/settings/#jwe_encryption_alg","title":"<code>JWE_ENCRYPTION_ALG</code>","text":"<p>The value used for <code>alg</code> in the JOSE header of the JWE.</p> <p>See the Eligibility API\u2019s documentation on Composing a message.</p>"},{"location":"configuration/settings/#jws_signing_alg","title":"<code>JWS_SIGNING_ALG</code>","text":"<p>The value used for <code>alg</code> in the JOSE header of the JWS</p> <p>See the Eligibility API\u2019s documentation on Composing a message.</p>"},{"location":"configuration/settings/#server_private_key_path","title":"<code>SERVER_PRIVATE_KEY_PATH</code>","text":"<p>The path to the server\u2019s private key, stored as a PEM text file. Used to decrypt the client\u2019s request and sign the server\u2019s response.</p> <p>Can be a path to a local file or a remote URL. For URLs, a simple anonymous GET request is made.</p>"},{"location":"configuration/settings/#server_public_key_path","title":"<code>SERVER_PUBLIC_KEY_PATH</code>","text":"<p>The path to the public key corresponding to the server\u2019s private key, stored as a PEM text file. Used by clients to encrypt requests sent to this server.</p> <p>Can be a path to a local file or a remote URL. For URLs, a simple anonymous GET request is made.</p>"},{"location":"configuration/settings/#sub_format_regex","title":"<code>SUB_FORMAT_REGEX</code>","text":"<p>A regular expression that the request\u2019s <code>sub</code> field must match.</p>"},{"location":"configuration/settings/#data-settings","title":"Data settings","text":""},{"location":"configuration/settings/#import_file_path","title":"<code>IMPORT_FILE_PATH</code>*","text":"<p>The path to file containing data to be imported into the server\u2019s database. Must be CSV.</p>"},{"location":"configuration/settings/#input_hash_algo","title":"<code>INPUT_HASH_ALGO</code>","text":"<p>Must be one of the types available in the <code>hashlib</code> library\u2019s <code>algorithms_available</code> function.</p>"},{"location":"configuration/settings/#csv-specific-settings","title":"CSV-specific settings","text":"<p>When using a CSV import file, the following variables can be configured:</p>"},{"location":"configuration/settings/#csv_delimiter","title":"<code>CSV_DELIMITER</code>","text":"<p>Specify a custom delimiter or use the default \u201c,\u201d</p>"},{"location":"configuration/settings/#csv_newline","title":"<code>CSV_NEWLINE</code>","text":"<p>Specify a newline or use the default of \u201c\u201d</p>"},{"location":"configuration/settings/#csv_quotechar","title":"<code>CSV_QUOTECHAR</code>","text":"<p>Specify a quote character or use the default of none</p>"},{"location":"configuration/settings/#csv_quoting","title":"<code>CSV_QUOTING</code>","text":"<p>Default of 3 (no quotes)</p> <p>These are the possible values for the <code>CSV_QUOTING</code> variable:</p> <ul> <li><code>csv.QUOTE_MINIMAL</code>: 0 - To be used when the CSV file has quotes around entries which contain special characters such as delimiters, quotechar or any of the characters in lineterminator</li> <li><code>csv.QUOTE_ALL</code>: 1 - To be used when all the values in the CSV file are present inside quotation marks</li> <li><code>csv.QUOTE_NONNUMERIC</code>: 2 - To be used when the CSV file uses quotes around non-numeric entries</li> <li><code>csv.QUOTE_NONE</code>: 3 - To be used when the CSV file does not use quotes around entries</li> </ul>"},{"location":"configuration/settings/#sentry","title":"Sentry","text":""},{"location":"configuration/settings/#sentry_dsn","title":"<code>SENTRY_DSN</code>","text":"<p>Cal-ITP\u2019s Sentry instance collects both errors (\u201cIssues\u201d) and app performance info.</p> <p>Alerts are sent to #benefits-notify in Slack. Others can be configured.</p> <p>You can troubleshoot Sentry itself by turning on debug mode and visiting <code>/error/</code>.</p> <p>Sentry docs</p> <p>Data Source Name (DSN)</p> <p>Enables sending events to Sentry.</p>"},{"location":"configuration/settings/#sentry_environment","title":"<code>SENTRY_ENVIRONMENT</code>","text":"<p>Sentry docs</p> <p><code>environment</code> config value</p> <p>Segments errors by which deployment they occur in. This defaults to <code>local</code>, and can be set to match one of the environment names.</p>"},{"location":"configuration/settings/#sentry_traces_sample_rate","title":"<code>SENTRY_TRACES_SAMPLE_RATE</code>","text":"<p>Sentry docs</p> <p><code>traces_sample_rate</code> config value</p> <p>Control the volume of transactions sent to Sentry. Value must be a float in the range <code>[0.0, 1.0]</code>.</p> <p>The default is <code>0.0</code> (i.e. no transactions are tracked).</p>"},{"location":"deployment/infrastructure/","title":"Infrastructure","text":"<p>The infrastructure is configured as code via Terraform, for various reasons.</p>"},{"location":"deployment/infrastructure/#architecture","title":"Architecture","text":""},{"location":"deployment/infrastructure/#resources-outside-of-terraform","title":"Resources outside of Terraform","text":"<p>The following things in Azure are managed outside of Terraform:</p> <ul> <li>Subcriptions</li> <li>Active Directory (users, groups, service principals, etc.)</li> <li>Service connections</li> <li>Configuration files, stored as blobs</li> <li>Role assignments</li> </ul>"},{"location":"deployment/infrastructure/#environments","title":"Environments","text":"Environment Azure Resource Group Terraform Workspace Git Reference Dev <code>$(AGENCY_RESOURCE_GROUP_PREFIX)-eligibility-dev</code> <code>dev</code> <code>main</code> Test <code>$(AGENCY_RESOURCE_GROUP_PREFIX)-eligibility-test</code> <code>test</code> release candidate tag Prod <code>$(AGENCY_RESOURCE_GROUP_PREFIX)-eligibility-prod</code> <code>default</code> release tag <p>(See Version number format for naming pattern for release candidate/release tags.)</p> <p>All resources in these Resource Groups should be reflected in Terraform in this repository. The exceptions are:</p> <ul> <li>Secrets, such as values under Key Vault. <code>prevent_destroy</code> is used on these Resources.</li> <li>Things managed outside of Terraform</li> </ul> <p>For browsing the Azure portal, you can switch your <code>Default subscription filter</code>.</p>"},{"location":"deployment/infrastructure/#access-restrictions","title":"Access restrictions","text":"<p>We restrict which IP addresses that can access the app service by using a Web Application Firewall (WAF) configured on a Front Door. There is an exception for the <code>/healthcheck</code> and <code>/static</code> paths, which can be accessed by any IP address.</p> <p>The app service itself gives access only to our Front Door and to Azure availability tests.</p>"},{"location":"deployment/infrastructure/#monitoring","title":"Monitoring","text":"<p>We have ping tests set up to notify about availability of each environment. Alerts go to #benefits-notify.</p>"},{"location":"deployment/infrastructure/#logs","title":"Logs","text":"<p>Logs can be found a couple of places:</p>"},{"location":"deployment/infrastructure/#azure-app-service-logs","title":"Azure App Service Logs","text":"<p>Open the <code>Logs</code> for the environment you are interested in. The following tables are likely of interest:</p> <ul> <li><code>AppServiceConsoleLogs</code>: <code>stdout</code> and <code>stderr</code> coming from the container</li> <li><code>AppServiceHTTPLogs</code>: requests coming through App Service</li> <li><code>AppServicePlatformLogs</code>: deployment information</li> </ul> <p>For some pre-defined queries, click <code>Queries</code>, then <code>Group by: Query type</code>, and look under <code>Query pack queries</code>.</p>"},{"location":"deployment/infrastructure/#azure-monitor-logs","title":"Azure Monitor Logs","text":"<p>Open the <code>Logs</code> for the environment you are interested in.</p> <p>The following tables are likely of interest:</p> <ul> <li><code>requests</code></li> <li><code>traces</code></li> </ul> <p>In the latter two, you should see recent log output. Note there is some latency.</p> <p>See <code>Failures</code> in the sidebar (or <code>exceptions</code> under <code>Logs</code>) for application errors/exceptions.</p>"},{"location":"deployment/infrastructure/#live-tail","title":"Live tail","text":"<p>After setting up the Azure CLI, you can use the following command to stream live logs:</p> <pre><code>az webapp log tail --resource-group &lt;resource group name&gt; --name &lt;app service name&gt; 2&gt;&amp;1 | grep -v /healthcheck\n</code></pre> <p>e.g.</p> <pre><code>az webapp log tail --resource-group courtesy-cards-eligibility-prod --name mst-courtesy-cards-eligibility-server-prod 2&gt;&amp;1 | grep -v /healthcheck\n</code></pre>"},{"location":"deployment/infrastructure/#scm","title":"SCM","text":"<p>Docker logs can be viewed in the Advanced Tools for the instance. The URL pattern is <code>https://&lt;app service name&gt;.scm.azurewebsites.net/api/logs/docker</code></p>"},{"location":"deployment/infrastructure/#making-changes","title":"Making changes","text":"<p>Terraform is <code>plan</code>\u2018d when commits that change any file under the <code>terraform</code> directory are either:</p> <ul> <li>merged into the <code>main</code> branch</li> <li>tagged with a release candidate or release tag</li> </ul> <p>Then, the Azure DevOps pipeline that ran the <code>plan</code> will wait for approval to run <code>apply</code>.</p> <p>While other automation for this project is done through GitHub Actions, we use an Azure DevOps Pipeline (above) for a couple of reasons:</p> <ul> <li>Easier authentication with the Azure API using a service connnection</li> <li>Log output is hidden, avoiding accidentally leaking secrets</li> </ul>"},{"location":"deployment/infrastructure/#local-development","title":"Local development","text":"<ol> <li>Get access to the Azure account.</li> <li> <p>Install dependencies:</p> </li> <li> <p>Azure CLI</p> </li> <li> <p>Terraform - see exact version in <code>pipeline/deploy.yml</code></p> </li> <li> <p>Authenticate using the Azure CLI.</p> </li> </ol> <pre><code>az login\n</code></pre> <ol> <li>Outside the dev container, navigate to the <code>terraform/</code> directory.</li> <li>Create a <code>terraform.tfvars</code> file and specify the variables.</li> <li>Initialize Terraform. You can also use this script later to switch between environments.</li> </ol> <pre><code>./init.sh &lt;env&gt; &lt;agency&gt;\n</code></pre> <ol> <li>Make changes to Terraform files.</li> <li>Preview the changes, as necessary.</li> </ol> <pre><code>terraform plan\n</code></pre> <ol> <li>Submit the changes via pull request.</li> </ol>"},{"location":"deployment/infrastructure/#azure-environment-setup","title":"Azure environment setup","text":"<p>The steps we took to set up MST\u2019s environment are documented in a separate Google Doc.</p> <p>In general, the steps that must be done manually before the pipeline can be run are:</p> <ul> <li>Create an Azure DevOps organization and project</li> <li>Request a free grant of parallel jobs using the form at https://aka.ms/azpipelines-parallelism-request</li> <li>Create Resource Group and storage account dedicated to the Terraform state</li> <li>Create container in storage account for Terraform state</li> <li>Create environment Resource Group for each environment, Region: West US</li> <li>We create these manually to avoid having to give the pipeline service connection permissions for creating resource groups</li> <li>Create Terraform workspace for each environment</li> <li>Trigger a pipeline run to verify <code>plan</code> and <code>apply</code></li> <li>Known chicken-and-egg problem: Terraform both creates the Key Vault and expects a secret within it, so will always fail on the first deploy. Add the Benefits slack email secret and re-run the pipeline.</li> </ul> <p>Once the pipeline has run, there are a few more steps to be done manually in the Azure portal. These are related to configuring the service principal used for ETL:</p> <ul> <li>Create the service principal</li> <li>Give the ETL service principal access to the <code>prod</code> storage account created by the pipeline:</li> <li>Navigate to the storage account container</li> <li>Select Access Control (IAM)</li> <li>Select Add, then select Add role assignment</li> <li>In the Role tab, select <code>Storage Blob Data Contributor</code></li> <li>In the Members tab, select <code>Select Members</code> and search for the ETL service principal. Add it to the role.</li> <li>Also in the Members tab, add a description of <code>This role assignment gives write access only for the path of the hashed data file.</code></li> <li>In the Conditions tab, select Add condition and change the editor type to <code>Code</code></li> <li>Add the following condition into the editor, filling in <code>&lt;filename&gt;</code> with the appropriate value:</li> </ul> <pre><code>(\n (\n  @Resource[Microsoft.Storage/storageAccounts/blobServices/containers/blobs:path] StringLike '&lt;filename&gt;'\n )\n)\n</code></pre>"}]}